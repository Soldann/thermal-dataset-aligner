# ===== Select Dataset =====
[Dataset]
# Options: VIGOR, RobotCar
dataset = RGBT_Scenes


# ===== VIGOR Dataset Configuration =====
[VIGOR]
local_dataset_root = /home/ziminxia/Work/datasets/VIGOR
scitas_dataset_root = /work/vita/datasets/VIGOR

batch_size = 1

# Image Sizes (Height, Width)
ground_image_size = (714, 1428)
satellite_image_size = (630, 630)

# BEV grid size in meters
grid_size_h = 71
grid_size_v = 20

random_orientation = 0

# ===== Oxford RobotCar Dataset Configuration =====
[RobotCar]
local_dataset_root = /home/ziminxia/Work/datasets/Oxford_5m_sampling
scitas_dataset_root = /work/vita/datasets/Oxford_5m_sampling

batch_size = 1

# Image Sizes (Height, Width)
raw_ground_image_size = (960, 1280)
cropped_ground_image_size = (800, 1200)
ground_image_size = (798, 1190)
satellite_image_size = (798, 798)

# BEV grid size in meters
grid_size_h = 73.73800466964494
grid_size_v = 20

# RGBT_Scenes
[RGBT_Scenes]
local_dataset_root = /home/landson/RGBT-Scenes/Building
scitas_dataset_root = /work/vita/datasets/Oxford_5m_sampling

batch_size = 1

# Image Sizes (Height, Width)
raw_ground_image_size = (480, 640)
cropped_ground_image_size = (480, 640)
ground_image_size = (392, 518)
satellite_image_size = (392, 518)

# BEV grid size in meters
grid_size_h = 73.73800466964494
grid_size_v = 20

# ===== Training Parameters =====
[Training]

learning_rate = 1e-4
epoch_to_resume = 0

# ===== Model Parameters =====
[Model]
grd_bev_res = 37
grd_height_res = 28
sat_bev_res = 37
num_keypoints = 256


# ===== Matching Parameters =====
[Matching]
num_samples_matches = 1024


# ===== Loss Parameters =====
[Loss]
beta = 1.0
loss_grid_size = 7.5
num_virtual_point = 10


# ===== Random Seed =====
[RandomSeed]
seed = 0
