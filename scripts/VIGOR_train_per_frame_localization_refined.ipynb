{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c4907-02c3-4faf-81ea-7a11e88d04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"10\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"10\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"10\" \n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "\n",
    "# Load configuration\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"./config.ini\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from dataloader_vigor import VIGORDataset, transform_grd, transform_sat\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "from utils import weighted_procrustes_2d\n",
    "from loss import loss_bev_space, compute_infonce_loss\n",
    "from model import CVM\n",
    "from modules import DinoExtractor\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility from config\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(mode=True, warn_only=True)\n",
    "\n",
    "set_seeds(config.getint(\"RandomSeed\", \"seed\"))\n",
    "\n",
    "# Load hyperparameters from config\n",
    "dataset_root = config[\"Datasets\"][\"dataset_root\"]\n",
    "batch_size = config.getint(\"Training\", \"batch_size\")\n",
    "learning_rate = config.getfloat(\"Training\", \"learning_rate\")\n",
    "learning_rate = 1e-4\n",
    "random_orientation = config.getint(\"Training\", \"random_orientation\")\n",
    "epoch_to_resume = config.getint(\"Training\", \"epoch_to_resume\")\n",
    "\n",
    "grd_bev_res = config.getint(\"Model\", \"grd_bev_res\")\n",
    "grd_height_res = config.getint(\"Model\", \"grd_height_res\")\n",
    "sat_bev_res = config.getint(\"Model\", \"sat_bev_res\")\n",
    "grid_size_h = config.getint(\"Model\", \"grid_size_h\")\n",
    "grid_size_v = config.getint(\"Model\", \"grid_size_v\")\n",
    "num_keypoints = config.getint(\"Model\", \"num_keypoints\")\n",
    "\n",
    "num_samples_matches = config.getint(\"Matching\", \"num_samples_matches\")\n",
    "\n",
    "beta = config.getfloat(\"Loss\", \"beta\")\n",
    "loss_grid_size = config.getfloat(\"Loss\", \"loss_grid_size\")\n",
    "num_virtual_point = config.getint(\"Loss\", \"num_virtual_point\")\n",
    "\n",
    "# Load image size from config\n",
    "ground_image_size = (config.getint(\"ImageSize\", \"ground_image_height\"), config.getint(\"ImageSize\", \"ground_image_width\"))\n",
    "satellite_image_size = (config.getint(\"ImageSize\", \"satellite_image_height\"), config.getint(\"ImageSize\", \"satellite_image_width\"))\n",
    "\n",
    "print(f\"Ground Image Size: {ground_image_size}, Satellite Image Size: {satellite_image_size}\")\n",
    "\n",
    "# Load dataset\n",
    "vigor = VIGORDataset(\n",
    "    root=dataset_root, split=\"samearea\", train=True, pos_only=True, \n",
    "    transform=(transform_grd, transform_sat), random_orientation=random_orientation\n",
    ")\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "dataset_length = len(vigor)\n",
    "indices = np.arange(dataset_length)\n",
    "np.random.shuffle(indices)\n",
    "split_idx = int(dataset_length * 0.8)\n",
    "\n",
    "# train_indices, val_indices = indices[:split_idx], indices[split_idx:]\n",
    "train_indices, val_indices = indices[:1], indices[:1]\n",
    "training_set, val_set = Subset(vigor, train_indices), Subset(vigor, val_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Generate label for logging\n",
    "label = (f\"debug_samearea_random_ori_{random_orientation}_num_matches_{num_samples_matches}\"\n",
    "         f\"_beta_{beta}_grd_bev_res_{grd_bev_res}_height_res_{grd_height_res}\"\n",
    "         f\"_sat_res_{sat_bev_res}_loss_grid_{loss_grid_size}\"\n",
    "         f\"_h_{grid_size_h}_v_{grid_size_v}_lr_{learning_rate}\")\n",
    "\n",
    "print(f\"Experiment label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5182239-7cc5-4ec8-a62b-2264a403fcb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Free unused memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize shared feature extractor\n",
    "shared_feature_extractor = DinoExtractor().to(device)\n",
    "\n",
    "# Initialize CVM Model\n",
    "CVM_model = CVM(device, grd_bev_res=grd_bev_res, grd_height_res=grd_height_res, \n",
    "                sat_bev_res=sat_bev_res, num_keypoints=num_keypoints, \n",
    "                embed_dim=1024, grid_size_h=grid_size_h, grid_size_v=grid_size_v)\n",
    "\n",
    "# Load checkpoint if resuming training\n",
    "if epoch_to_resume > 0:\n",
    "    model_path = f'/work/vita/zimin/CVM_3D/checkpoints/{label}/{epoch_to_resume-1}/model.pt'\n",
    "    CVM_model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "CVM_model.to(device)\n",
    "CVM_model.train()\n",
    "\n",
    "# Enable gradient updates for model parameters\n",
    "for param in CVM_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Set up optimizer\n",
    "params = [p for p in CVM_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "# Setup TensorBoard logging\n",
    "writer_dir = f'../tensorboard/{label}/'\n",
    "os.makedirs(writer_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=writer_dir)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "# Define metric grids for training\n",
    "def create_metric_grid(grid_size, res, batch_size):\n",
    "    x, y = np.linspace(-grid_size/2, grid_size/2, res), np.linspace(-grid_size/2, grid_size/2, res)\n",
    "    metric_x, metric_y = np.meshgrid(x, y, indexing='ij')\n",
    "    metric_x, metric_y = torch.tensor(metric_x).flatten().unsqueeze(0).unsqueeze(-1), torch.tensor(metric_y).flatten().unsqueeze(0).unsqueeze(-1)\n",
    "    metric_coord = torch.cat((metric_x, metric_y), -1).to(device).float()\n",
    "    return metric_coord.repeat(batch_size, 1, 1)\n",
    "\n",
    "metric_coord_grd_B = create_metric_grid(grid_size_h, grd_bev_res, batch_size)\n",
    "metric_coord_sat_B = create_metric_grid(grid_size_h, sat_bev_res, batch_size)\n",
    "metric_coord4loss = create_metric_grid(loss_grid_size, num_virtual_point, batch_size)\n",
    "\n",
    "# -------------------------\n",
    "# Training Loop\n",
    "# -------------------------\n",
    "for epoch in range(epoch_to_resume, 20000):\n",
    "    # print(f'üöÄ Epoch {epoch} - Training...')\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    CVM_model.train()\n",
    "\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        grd, sat, tgt, Rgt, city = data\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        B, _, sat_size, _ = sat.shape\n",
    "\n",
    "        # Normalize ground truth translation\n",
    "        tgt = (tgt / sat_size) * grid_size_h\n",
    "\n",
    "        # Move data to device\n",
    "        grd, sat, tgt, Rgt = grd.to(device), sat.to(device), tgt.to(device), Rgt.to(device)\n",
    "\n",
    "        # Forward pass through the feature extractor\n",
    "        grd_feature, sat_feature = shared_feature_extractor(grd), shared_feature_extractor(sat)     \n",
    "\n",
    "        # Obtain matching scores and descriptors\n",
    "        matching_score, sat_desc, grd_desc, sat_indices_topk, grd_indices_topk, matching_score_original = CVM_model(grd_feature, sat_feature)\n",
    "        \n",
    "        # Sample matching points\n",
    "        _, num_kpts_sat, num_kpts_grd = matching_score.shape\n",
    "        matches_row = matching_score.flatten(1)\n",
    "\n",
    "        batch_idx = torch.arange(B).view(B, 1).repeat(1, num_samples_matches).reshape(B, num_samples_matches)\n",
    "        sampled_matching_idx = torch.multinomial(matches_row, num_samples_matches)\n",
    "\n",
    "        sampled_matching_row = torch.div(sampled_matching_idx, num_kpts_grd, rounding_mode='trunc')\n",
    "        sampled_matching_col = sampled_matching_idx % num_kpts_grd\n",
    "\n",
    "        sat_indices_sampled = torch.gather(sat_indices_topk.squeeze(1), 1, sampled_matching_row) # indices for flattened sat BEV points\n",
    "        grd_indices_sampled = torch.gather(grd_indices_topk.squeeze(1), 1, sampled_matching_col) # indices for flattened grd BEV points\n",
    "        \n",
    "            \n",
    "        # Compute transformation using Weighted Procrustes\n",
    "        X, Y, weights = metric_coord_sat_B[batch_idx, sat_indices_sampled, :], metric_coord_grd_B[batch_idx, grd_indices_sampled, :], matches_row[batch_idx, sampled_matching_idx]\n",
    "        R, t, ok_rank = weighted_procrustes_2d(X, Y, use_weights=True, use_mask=True, w=weights)\n",
    "\n",
    "        if t is None:\n",
    "            print('‚ö†Ô∏è Skipping batch: Singular transformation matrix')\n",
    "            continue\n",
    "\n",
    "        # # Compute distance loss\n",
    "        distance_loss = loss_bev_space(metric_coord4loss, Rgt, tgt, R, t)\n",
    "\n",
    "        # Compute similarity loss\n",
    "        batch_idx_kpt = torch.arange(B).view(B, 1).repeat(1, num_keypoints).reshape(B, num_keypoints)\n",
    "        sat_keypoint_coord, grd_keypoint_coord = metric_coord_sat_B[batch_idx_kpt, sat_indices_topk.squeeze(1), :], metric_coord_grd_B[batch_idx_kpt, grd_indices_topk.squeeze(1), :]\n",
    "        infonce_loss = compute_infonce_loss(Rgt, tgt, X, Y, sampled_matching_row, sampled_matching_col, sat_indices_topk.squeeze(1), grd_indices_topk.squeeze(1), sat_keypoint_coord, grd_keypoint_coord, matching_score_original)\n",
    "        \n",
    "        # avg_loss = torch.mean(distance_loss) + beta * torch.mean(infonce_loss)\n",
    "        avg_loss = torch.mean(infonce_loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        avg_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log training loss\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, global_step)\n",
    "        global_step += 1\n",
    "\n",
    "    # # -------------------------\n",
    "    # # Validation Every 10 Epochs\n",
    "    # # -------------------------\n",
    "    # if epoch % 10 == 0:\n",
    "    #     print(f'üìä Epoch {epoch} - Evaluating on validation set...')\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         CVM_model.eval()\n",
    "    #         translation_error, yaw_error = [], []\n",
    "\n",
    "            for i, data in enumerate(val_dataloader, 0):\n",
    "                grd, sat, tgt, Rgt, city = data\n",
    "                B, _, sat_size, _ = sat.shape\n",
    "\n",
    "    #             grd, sat, tgt, Rgt = grd.to(device), sat.to(device), tgt.to(device), Rgt.to(device)\n",
    "\n",
    "                grd_feature, sat_feature = shared_feature_extractor(grd), shared_feature_extractor(sat)\n",
    "        \n",
    "                matching_score, sat_desc, grd_desc, sat_indices_topk, grd_indices_topk, matching_score_original = CVM_model(grd_feature, sat_feature)\n",
    "\n",
    "    #             # Sample validation matches\n",
    "    #             matches_row = matching_score.flatten(1)\n",
    "    #             batch_idx = torch.arange(B).view(B, 1).repeat(1, num_samples_matches).reshape(B, num_samples_matches)\n",
    "    #             sampled_matching_idx = torch.multinomial(matches_row, num_samples_matches)\n",
    "\n",
    "                sampled_matching_row = torch.div(sampled_matching_idx, num_kpts_grd, rounding_mode='trunc')\n",
    "                sampled_matching_col = sampled_matching_idx % num_kpts_grd\n",
    "\n",
    "                sat_indices_sampled = torch.gather(sat_indices_topk.squeeze(1), 1, sampled_matching_row)\n",
    "                grd_indices_sampled = torch.gather(grd_indices_topk.squeeze(1), 1, sampled_matching_col)\n",
    "\n",
    "    #             X, Y, weights = metric_coord_sat_B[batch_idx, sat_indices_sampled, :], metric_coord_grd_B[batch_idx, grd_indices_sampled, :], matches_row[batch_idx, sampled_matching_idx]\n",
    "    #             R, t, ok_rank = weighted_procrustes_2d(X, Y, use_weights=True, use_mask=True, w=weights)\n",
    "\n",
    "    #             if t is None:\n",
    "    #                 print('‚ö†Ô∏è Skipping batch: Singular transformation matrix')\n",
    "    #                 continue\n",
    "                \n",
    "    #             # Compute translation error\n",
    "    #             t = (t / grid_size_h) * sat_size\n",
    "    #             translation_error.extend(torch.norm(t - tgt, dim=-1).cpu().numpy())\n",
    "\n",
    "                # Compute yaw error\n",
    "                Rgt_np, R_np = Rgt.cpu().numpy(), R.cpu().numpy()\n",
    "                for b in range(B):\n",
    "                    cos = R_np[b,0,0]\n",
    "                    sin = R_np[b,1,0]\n",
    "                    yaw = np.degrees( np.arctan2(sin, cos) )            \n",
    "                    \n",
    "                    cos_gt = Rgt_np[b,0,0]\n",
    "                    sin_gt = Rgt_np[b,1,0]\n",
    "                    \n",
    "                    yaw_gt = np.degrees( np.arctan2(sin_gt, cos_gt) )\n",
    "                    \n",
    "                    diff = np.abs(yaw - yaw_gt)\n",
    "        \n",
    "                    yaw_error.append(np.min([diff, 360-diff]))                \n",
    "\n",
    "                \n",
    "            print(f'üìâ Mean Translation Error: {np.mean(translation_error):.3f}')\n",
    "            print(f'üìâ Mean Yaw Error: {np.mean(yaw_error):.3f}')\n",
    "\n",
    "writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d101f-4901-4e24-9e82-51467a7e5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
